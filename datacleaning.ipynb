{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datacleaning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samreeneducation/thesis/blob/master/datacleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIT4gA3yGsqI",
        "colab_type": "text"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnngM-VJNbj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbIQD77hX7gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import textblob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiJjG9ujEZgq",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "import string \n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4peAIDyHDbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7kPUIi36EF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IH02G29Ps1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation \n",
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22BZ84O801eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import  TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcLT9qvn5dcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGkRmqhzG1Vk",
        "colab_type": "text"
      },
      "source": [
        "datset upload and storing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdwf3Gz6Fnvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VltOMEiLU8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"auspol2019.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZYaSRd1HMEc",
        "colab_type": "text"
      },
      "source": [
        "dataset information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xH-tm2nLtIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEapJaiEWu7v",
        "colab_type": "text"
      },
      "source": [
        "adding sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyiVIvdBWTS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tweet(full_text):\n",
        "    return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', full_text).split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3LKbF6yWrkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_sentiment(full_text\t):\n",
        "    analysis = TextBlob(full_text\t)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif analysis.sentiment.polarity ==0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Negative'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQX7Xc3cXrNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Sentiment'] = df['full_text'].apply(lambda x: analyze_sentiment(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF5aCxUzY7lJ",
        "colab_type": "text"
      },
      "source": [
        "Data cleaning and preprcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUp98NU9YuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "example1 = BeautifulSoup(df.full_text[3], 'lxml')\n",
        "#print example1.get_text()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agsOnT8z3obS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop any rows which have any nans\n",
        "df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZisjIv9eXbcX",
        "colab_type": "text"
      },
      "source": [
        "First define the data cleaning function, include the above five data cleaning tasks, and then apply it to the entire data set. Word segmentation, stemming / morphization, stop words will be used later when creating matrices with count vectorizer and Tfidf vectorizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AnG2FBi9EUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "def tweet_cleaner(full_text):\n",
        "    soup = BeautifulSoup(\n",
        "        full_text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
        "    # I will tokenize and join together to remove unneccessary white spaces\n",
        "    words = tok.tokenize(lower_case)\n",
        "    return (\" \".join(words)).strip()\n",
        "testing = df.full_text[0:183378]\n",
        "test_result = []\n",
        "for t in testing:\n",
        "    test_result.append(tweet_cleaner(t))\n",
        "test_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1mLHW4KLpBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "def tweet_cleaner(full_text):\n",
        "    soup = BeautifulSoup(full_text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
        "    # I will tokenize and join together to remove unneccessary white spaces\n",
        "    words = tok.tokenize(lower_case)\n",
        "    return (\" \".join(words)).strip()\n",
        "testing = df.full_text[0:183378]\n",
        "test_result = []\n",
        "for t in testing:\n",
        "    test_result.append(tweet_cleaner(t))\n",
        "test_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcy92zE50BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = df.full_text[0:183378]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmbZUUHB681z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing.replace(u\"\\ufffd\", \"?\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJRu1yD5NE8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nums = [0,183378]\n",
        "print(\"Cleaning and parsing the tweets...\\n\")\n",
        "clean_tweet_texts = []\n",
        "for i in range(nums[0],nums[1]):\n",
        "    if( (i+1)%10000 == 0 ):\n",
        "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1]))                                                                    \n",
        "    clean_tweet_texts.append(tweet_cleaner(df['full_text'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkdJmCV9OgMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "clean_df['Sentiment'] = df.Sentiment\n",
        "clean_df['retweet_count']=df.retweet_count\n",
        "clean_df['created_at']=df.created_at\n",
        "clean_df['user_location']=df.user_location\n",
        "clean_df['user_name']=df.user_name\n",
        "clean_df['user_screen_name']=df.user_screen_name\n",
        "clean_df['user_description']=df.user_description\n",
        "clean_df['user_id']=df.user_id\n",
        "clean_df['user_created_at']=df.user_created_at\n",
        "clean_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9PIubycQIDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4FT27sTZkZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df = pd.DataFrame(clean_tweet_texts,columns=['full_text'])\n",
        "clean_df['Sentiment'] = df.Sentiment\n",
        "clean_df['retweet_count']=df.retweet_count\n",
        "clean_df['user_location\t']=df.user_location\n",
        "clean_df['user_screen_name\t']=df.user_screen_name\n",
        "clean_df['user_description']=df.user_description\n",
        "clean_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQHRv5fcbwk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyaH17jne8pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df.to_csv('clean_tweet.csv',encoding='utf-8')\n",
        "csv = 'clean_tweet.csv'\n",
        "my_df = pd.read_csv(csv,index_col=0)\n",
        "my_df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTwE0LUvf6PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_df =my_df.dropna(axis = 0, how ='any') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x8HBgEEgPLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_df.head(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dqoP0g2gLJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5szfZ_mhHnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download(\"clean_tweet.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}